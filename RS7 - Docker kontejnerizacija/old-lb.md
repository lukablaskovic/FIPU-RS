# 3 Load balancing (Raspodjela optereÄ‡enja mikroservisa)

**Load balancing** je tehnika koja se koristi za distribuciju optereÄ‡enja izmeÄ‘u viÅ¡e posluÅ¾itelja, raÄunala ili mreÅ¾nih ureÄ‘aja. Ova tehnika omoguÄ‡uje da se optereÄ‡enje ravnomjerno raspodijeli izmeÄ‘u viÅ¡e posluÅ¾itelja, kako bi se osigurala visoka dostupnost i pouzdanost sustava.

Ciljevi load balancinga su sljedeÄ‡i:

- **Ravnomjerna raspodjela optereÄ‡enja** - svaki posluÅ¾itelj dobiva jednaku koliÄinu zahtjeva
- **Visoka dostupnost** - ako jedan posluÅ¾itelj prestane raditi, drugi preuzimaju njegovo optereÄ‡enje
- **Prevencija da jedan posluÅ¾itelj postane usko grlo** - ako jedan posluÅ¾itelj postane preoptereÄ‡en, load balancer preusmjerava zahtjeve na druge posluÅ¾itelje
- **PoveÄ‡anje performansi** - load balancer moÅ¾e koristiti razliÄite algoritme za raspodjelu optereÄ‡enja, ovisno o potrebama sustava

Postoje razliÄite vrste load balancera, meÄ‘utim mi se neÄ‡emo baviti detaljima. U ovom primjeru koristit Ä‡emo **nginx** kao load balancer za naÅ¡e mikroservise.

**nginx** je popularan web posluÅ¾itelj i _reverse proxy server_ koji se koristi za posluÅ¾ivanje web stranica, aplikacija i API-ja. Osim toga, **nginx** se moÅ¾e koristiti kao load balancer za distribuciju optereÄ‡enja izmeÄ‘u viÅ¡e posluÅ¾itelja.

<img src="https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcQc3C0LvR8Dxa_867W0XUhkdNX3UA9KmBDK_w&s" style="width:50%;"></img>

> Ilustracija rada load balancera

`nginx` nije dio Dockera, niti Pythona, veÄ‡ je zaseban softver koji se moÅ¾e instalirati na raÄunalo.

MeÄ‘utim, moÅ¾emo koristiti `nginx` kao Docker kontejner i konfigurirati ga kao load balancer za naÅ¡e mikroservise.

MoÅ¾emo ga preuzeti preko Docker Huba, na sljedeÄ‡oj poveznici: [https://hub.docker.com/\_/nginx](https://hub.docker.com/_/nginx)

```bash
docker pull nginx
```

**Dokumentacija**: [https://nginx.org/en/docs/](https://nginx.org/en/docs/)

## 3.1 Horizontalno skaliranje koristeÄ‡i samo Docker Compose

**Horizontalno skaliranje** (_eng. Horizontal scaling_) mikroservisa odnosi se na poveÄ‡anje broja instanci mikroservisa kako bi se poveÄ‡ala dostupnost i performanse sustava. Primjerice, ako iz naÅ¡eg primjera imamo samo jednu instancu `weather-fastapi` mikroservisa, moÅ¾emo dodati joÅ¡ jednu instancu u sluÄaju da prva prestane raditi.

Dakle, u ovom kontekstu samo poveÄ‡avamo **broj instanci mikroservisa**.

<img src="https://github.com/lukablaskovic/FIPU-RS/blob/main/RS7%20-%20Kontejnerizacija%20i%20Load%20balancing/screenshots/horizonta-scaling.png?raw=true" style="width:50%;"></img>

> Ilustracija horizontalnog skaliranja mikroservisa

Na primjer, Å¾elimo dodati 3 replike `weather-fastapi` mikroservisa i 2 replike `aiohttp-regije` mikroservisa. To radimo kroz `docker-compose.yml` datoteku:

_Sintaksa:_

```yaml
version: "3.8"

services:
  naziv_servisa:
    image: ime_docker_predloska
    ports:
      - "host_port:container_port"
    deploy:
      replicas: broj_replika
```

Odnosno na naÅ¡em primjeru:

```yaml
version: "3.8"

services:
  aiohttp-regije:
    image: aiohttp-regije:1.0
    ports:
      - "${PORT}:${PORT}"
    env_file:
      - .env
    networks:
      - interna_mreza
    deploy:
      replicas: 2

  weather-fastapi:
    image: weather-fastapi:1.0
    ports:
      - "8000:8000"
    networks:
      - interna_mreza
    deploy:
      replicas: 3

networks:
  interna_mreza: # proizvoljno ime mreÅ¾e
    driver: bridge # tip mreÅ¾e
```

MoÅ¾emo pokrenuti ove kontejnere, meÄ‘utim dobit Ä‡emo **greÅ¡ku** prilikom pokretanja buduÄ‡i da Docker pokuÅ¡ava mapirati isti port na viÅ¡e kontejnera prema domaÄ‡inu, Å¡to nije dozvoljeno.

<img src="https://github.com/lukablaskovic/FIPU-RS/blob/main/RS7%20-%20Kontejnerizacija%20i%20Load%20balancing/screenshots/docker-compose-swarm-problem.png?raw=true" style="width:80%;"></img>

Problem moÅ¾emo rijeÅ¡iti koristeÄ‡i **nginx** kao load balancer koji Ä‡e **distribuirati zahtjeve na razliÄite mikroservise**.

Prvo Ä‡emo dodati `nginx` kontejner u `docker-compose.yml` datoteku:

- radi pojednostavljenja, trenutno Ä‡emo maknuti dinamiÄko mapiranje portova i staviti fiksne portove za svaki mikroservis

```yaml
version: "3.8"

services:
  aiohttp-regije:
    image: aiohttp-regije:1.0
    ports:
      - "4000:4000" # fiksni port za aiohttp-regije
    networks:
      - interna_mreza
    deploy:
      replicas: 2

  weather-fastapi:
    image: weather-fastapi:1.0
    ports:
      - "8000:8000" # fiksni port za weather-fastapi
    networks:
      - interna_mreza
    deploy:
      replicas: 3

  nginx: # dodajemo nginx load balancer
    image: nginx
    ports:
      - "80:80"
    volumes: # mapiramo konfiguracijsku datoteku
      - ./nginx.conf:/etc/nginx/nginx.conf # konfiguracijska datoteka za nginx je nginx.conf
    networks:
      - interna_mreza

networks:
  interna_mreza: # proizvoljno ime mreÅ¾e
    driver: bridge # tip mreÅ¾e
```

`nginx` definiramo unutar konfiguracijske datoteke `nginx.conf` koja se mora nalaziti u istom direktoriju kao i `docker-compose.yml` datoteka:

Struktura direktorija:

```plaintext
compose-example/
  â”œâ”€â”€ aiohttp-regije/
  â”‚   â”œâ”€â”€ app.py
  â”‚   â”œâ”€â”€ requirements.txt
  â”‚   â”œâ”€â”€ Dockerfile
  â”œâ”€â”€ weather-fastapi/
  â”‚   â”œâ”€â”€ main.py
  â”‚   â”œâ”€â”€ models.py
  â”‚   â”œâ”€â”€ requirements.txt
  â”‚   â””â”€â”€ Dockerfile
  â”œâ”€â”€ nginx.conf
  â”œâ”€â”€ .env
  â””â”€â”€ docker-compose.yml
```

**Reverse proxy** odnosi se na tehniku koja omoguÄ‡uje da se zahtjevi preusmjere s jednog posluÅ¾itelja na drugi. U naÅ¡em sluÄaju, `nginx` Ä‡e **preusmjeravati zahtjeve na razliÄite mikroservise**. ViÅ¡e o ovoj temi proÄitajte na sljedeÄ‡oj [poveznici](https://www.zscaler.com/resources/security-terms-glossary/what-is-reverse-proxy).

Unutar `nginx.conf` datoteke, prvo Ä‡emo definirati `upstream` blok u kojem Ä‡emo navesti sve mikroservise na koje Ä‡e `nginx` preusmjeravati zahtjeve, to su `aiohttp-regije` i `weather-fastapi` mikroservisi:

**VAÅ½NO!** Bez obzira na interne portove unutar kontejnera, ovdje moÅ¾emo definirati na koje portove Ä‡e `nginx` preusmjeravati zahtjeve, odnosno koje portove Ä‡e koristiti domaÄ‡in (**krajnji korisnik**).

Trenutni portovi definirani unutar `docker-compose.yml` su:

- `aiohttp-regije`: `4000`
- `weather-fastapi`: `8000`

Otvorite `nginx.conf` datoteku:

1. korak: definicija `events` bloka gdje navodimo najveÄ‡i broj konekcija koje `nginx` moÅ¾e obraditi istovremeno

```plaintext
events {
    worker_connections 1024;
}
```

2. korak: definicija `http` bloka gdje navodimo `upstream` blok i `server` blok

Prvo Ä‡emo navesti `upstream` blokove u kojima navodimo naÅ¡e mikroservise:

```plaintext
http {
  upstream aiohttp-regije {
    server aiohttp-regije:4000;
  }

  upstream weather-fastapi {
    server weather-fastapi:8000;
  }
}
```

3. korak: definiramo _reverse-proxy_ na proizvoljnom portu (npr. `80`) i **preusmjeravamo sve zahtjeve** na `aiohttp-regije` i `weather-fastapi` mikroservise:

- na lokaciji `/aiohttp` preusmjeravamo sve zahtjeve na `aiohttp-regije` mikroservis
- na lokaciji `/fastapi` preusmjeravamo sve zahtjeve na `weather-fastapi` mikroservis

Ukupna konfiguracija `nginx.conf` datoteke:

```nginx
events {
    worker_connections 1024;
}


http {

upstream aiohttp-regije {
  server aiohttp-regije:4000;
}

upstream weather-fastapi {
  server weather-fastapi:8000;
}


server {
    listen 80;

    location /aiohttp {
        proxy_pass http://aiohttp-regije;
        proxy_set_header Host $host;
        proxy_set_header X-Real-IP $remote_addr;
        proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
    }

    location /fastapi {
        proxy_pass http://weather-fastapi;
        proxy_set_header Host $host;
        proxy_set_header X-Real-IP $remote_addr;
        proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
    }
}

}
```

Jednostavno pokreÄ‡emo opet mikroservise koristeÄ‡i `docker-compose up` naredbu:

```bash
docker compose up
```

Otvorite `http://localhost/aiohttp` i `http://localhost/fastapi` u web pregledniku i provjerite radi li load balancer kako treba.

Vidimo da nema greÅ¡aka, `nginx` uspjeÅ¡no preusmjerava zahtjeve na `aiohttp-regije` i `weather-fastapi` mikroservise.

```bash
nginx-1            | /docker-entrypoint.sh: /docker-entrypoint.d/ is not empty, will attempt to perform configuration
nginx-1            | /docker-entrypoint.sh: Looking for shell scripts in /docker-entrypoint.d/
nginx-1            | /docker-entrypoint.sh: Launching /docker-entrypoint.d/10-listen-on-ipv6-by-default.sh
nginx-1            | 10-listen-on-ipv6-by-default.sh: info: IPv6 listen already enabled
nginx-1            | /docker-entrypoint.sh: Sourcing /docker-entrypoint.d/15-local-resolvers.envsh
nginx-1            | /docker-entrypoint.sh: Launching /docker-entrypoint.d/20-envsubst-on-templates.sh
nginx-1            | /docker-entrypoint.sh: Launching /docker-entrypoint.d/30-tune-worker-processes.sh
nginx-1            | /docker-entrypoint.sh: Configuration complete; ready for start up
weather-fastapi-1  | INFO:     Started server process [1]
weather-fastapi-1  | INFO:     Waiting for application startup.
weather-fastapi-1  | INFO:     Application startup complete.
weather-fastapi-1  | INFO:     Uvicorn running on http://0.0.0.0:8000 (Press CTRL+C to quit)
nginx-1            | 172.20.0.1 - - [22/Jan/2025:08:12:35 +0000] "GET /aiohttp HTTP/1.1" 404 14 "-" "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/132.0.0.0 Safari/537.36"
weather-fastapi-1  | INFO:     172.20.0.4:59704 - "GET /fastapi HTTP/1.0" 404 Not Found
nginx-1            | 172.20.0.1 - - [22/Jan/2025:08:12:38 +0000] "GET /fastapi HTTP/1.1" 404 22 "-" "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/132.0.0.0 Safari/537.36"
nginx-1            | 172.20.0.1 - - [22/Jan/2025:08:16:49 +0000] "GET /aiohttp HTTP/1.1" 404 14 "-" "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/132.0.0.0 Safari/537.36"
weather-fastapi-1  | INFO:     172.20.0.4:33340 - "GET /fastapi HTTP/1.0" 404 Not Found
nginx-1            | 172.20.0.1 - - [22/Jan/2025:08:16:51 +0000] "GET /fastapi HTTP/1.1" 404 22 "-" "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/132.0.0.0 Safari/537.36"
```

Vidimo da u Docker Desktopu nemamo viÅ¡e duple instance `weather-fastapi` i `aiohttp-regije` mikroservisa, veÄ‡ samo jednu instancu svakog mikroservisa, a `nginx` uspjeÅ¡no preusmjerava zahtjeve na njih.

Dakle, **horizontalno skaliranje** mikroservisa moÅ¾emo postiÄ‡i kroz `docker-compose.yml` datoteku i `nginx` kao load balancer, a cijelu apstrakciju balansiranja izvrÅ¡ava sam `nginx` kontejner ğŸ˜

<img src="https://github.com/lukablaskovic/FIPU-RS/blob/main/RS7%20-%20Kontejnerizacija%20i%20Load%20balancing/screenshots/comopse-nginx-correct.png?raw=true" style="width:100%;"></img>

> Load balancer `nginx` uspjeÅ¡no preusmjerava zahtjeve na `aiohttp-regije` i `weather-fastapi` mikroservise
